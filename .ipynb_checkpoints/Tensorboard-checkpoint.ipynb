{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter: keep it first\n",
    "%matplotlib inline\n",
    "\n",
    "# --- CPU-friendly setup (must come before importing tensorflow) ---\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"   # force CPU (ignore NVIDIA GPUs)\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"1\"   # faster CPU kernels\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"         # tune for your CPU\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import ndimage\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# --- TensorFlow (CPU only) ---\n",
    "import tensorflow as tf\n",
    "\n",
    "# Extra safety: hide all accelerators (GPU/TPU/MPS) if present\n",
    "for dev_type in [\"GPU\", \"TPU\", \"MPS\"]:\n",
    "    try:\n",
    "        tf.config.set_visible_devices([], dev_type)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Keep TF thread usage reasonable on CPU (adjust to taste)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.keras.backend.set_floatx(\"float32\")\n",
    "\n",
    "# --- Keras / TF imports ---\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Activation, Dense, Dropout, Flatten,\n",
    "                                     BatchNormalization, Conv2D, MaxPooling2D)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# (Removed GPU-only code)\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Load training set and test set\n",
    "\n",
    "training_data = unpickle('/Users/pascal-maker/Desktop/deeplearning/Session_02_Convolutional_Neural_Networks_Demos/cifar-10/data_batch_1')\n",
    "test_data = unpickle('/Users/pascal-maker/Desktop/deeplearning/Session_02_Convolutional_Neural_Networks_Demos/cifar-10/test_batch')\n",
    "\n",
    "# Create training set and test set\n",
    "\n",
    "X_train = training_data.get(b'data')\n",
    "train_labels = training_data.get(b'labels')\n",
    "\n",
    "X_test = test_data.get(b'data')\n",
    "test_labels = test_data.get(b'labels')\n",
    "\n",
    "# Reshape into Tensorflow format (number of images, width, height, color channels)\n",
    "\n",
    "X_train = X_train.reshape((len(X_train),3,32,32)).transpose(0,2,3,1)\n",
    "X_test  = X_test.reshape((len(X_test),3,32,32)).transpose(0,2,3,1)\n",
    "\n",
    "# Normalisatie\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding of the labels\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'CIFAR-10_CNN_Dropout_10_Percent'.format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2770 - loss: 2.1100 - val_accuracy: 0.1530 - val_loss: 3.2487\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4547 - loss: 1.5161 - val_accuracy: 0.1030 - val_loss: 4.0849\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5357 - loss: 1.2988 - val_accuracy: 0.0995 - val_loss: 5.1461\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5794 - loss: 1.1554 - val_accuracy: 0.2865 - val_loss: 2.2666\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6118 - loss: 1.0939 - val_accuracy: 0.4190 - val_loss: 1.8222\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6322 - loss: 1.0263 - val_accuracy: 0.5505 - val_loss: 1.2796\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6511 - loss: 0.9600 - val_accuracy: 0.5510 - val_loss: 1.2915\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6826 - loss: 0.8801 - val_accuracy: 0.5735 - val_loss: 1.2301\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7083 - loss: 0.8226 - val_accuracy: 0.5760 - val_loss: 1.2286\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7331 - loss: 0.7601 - val_accuracy: 0.5865 - val_loss: 1.2203\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7489 - loss: 0.7118 - val_accuracy: 0.5940 - val_loss: 1.2183\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7590 - loss: 0.6786 - val_accuracy: 0.6030 - val_loss: 1.1979\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7752 - loss: 0.6376 - val_accuracy: 0.5680 - val_loss: 1.3542\n",
      "Epoch 14/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7698 - loss: 0.6338 - val_accuracy: 0.5995 - val_loss: 1.2541\n",
      "Epoch 15/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7968 - loss: 0.5768 - val_accuracy: 0.5780 - val_loss: 1.3398\n",
      "Epoch 16/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8054 - loss: 0.5477 - val_accuracy: 0.5825 - val_loss: 1.2966\n",
      "Epoch 17/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8148 - loss: 0.5074 - val_accuracy: 0.5715 - val_loss: 1.4456\n",
      "Epoch 18/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8101 - loss: 0.5370 - val_accuracy: 0.6015 - val_loss: 1.2846\n",
      "Epoch 19/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8358 - loss: 0.4703 - val_accuracy: 0.5890 - val_loss: 1.3399\n",
      "Epoch 20/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8293 - loss: 0.4808 - val_accuracy: 0.5590 - val_loss: 1.5108\n",
      "Epoch 21/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8552 - loss: 0.4289 - val_accuracy: 0.5900 - val_loss: 1.4068\n",
      "Epoch 22/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8573 - loss: 0.4081 - val_accuracy: 0.5915 - val_loss: 1.4480\n",
      "Epoch 23/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8592 - loss: 0.3926 - val_accuracy: 0.5775 - val_loss: 1.5025\n",
      "Epoch 24/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8572 - loss: 0.4084 - val_accuracy: 0.5950 - val_loss: 1.4396\n",
      "Epoch 25/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8657 - loss: 0.3752 - val_accuracy: 0.5800 - val_loss: 1.5080\n",
      "Epoch 26/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8691 - loss: 0.3620 - val_accuracy: 0.5750 - val_loss: 1.5697\n",
      "Epoch 27/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8783 - loss: 0.3503 - val_accuracy: 0.5830 - val_loss: 1.5135\n",
      "Epoch 28/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8791 - loss: 0.3496 - val_accuracy: 0.5770 - val_loss: 1.6568\n",
      "Epoch 29/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8891 - loss: 0.3275 - val_accuracy: 0.5510 - val_loss: 1.9448\n",
      "Epoch 30/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8855 - loss: 0.3161 - val_accuracy: 0.5870 - val_loss: 1.5959\n"
     ]
    }
   ],
   "source": [
    "# Neural network parameters\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "batch_size = 64 # \n",
    "epochs = 30 # \n",
    "dropoutRate = 0.1\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=input_shape)) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(dropoutRate)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(dropoutRate)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(dropoutRate)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trainen van het CNN\n",
    "history = model.fit(X_train, y_train,batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=1, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second model\n",
    "\n",
    "\n",
    "NAME = 'CIFAR-10_CNN_Dropout_30_Percent'.format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.1930 - loss: 2.5546 - val_accuracy: 0.1075 - val_loss: 2.6228\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3312 - loss: 1.8545 - val_accuracy: 0.1085 - val_loss: 2.6203\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3880 - loss: 1.6858 - val_accuracy: 0.2170 - val_loss: 2.1012\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4353 - loss: 1.5553 - val_accuracy: 0.3005 - val_loss: 1.9916\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4579 - loss: 1.4921 - val_accuracy: 0.4620 - val_loss: 1.4941\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4835 - loss: 1.4500 - val_accuracy: 0.4995 - val_loss: 1.3964\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5024 - loss: 1.3690 - val_accuracy: 0.5050 - val_loss: 1.3656\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5065 - loss: 1.3384 - val_accuracy: 0.5150 - val_loss: 1.3992\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5282 - loss: 1.3069 - val_accuracy: 0.5155 - val_loss: 1.3083\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5456 - loss: 1.2811 - val_accuracy: 0.5295 - val_loss: 1.2928\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5393 - loss: 1.2548 - val_accuracy: 0.5350 - val_loss: 1.3578\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5744 - loss: 1.1989 - val_accuracy: 0.4165 - val_loss: 1.7810\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5759 - loss: 1.1702 - val_accuracy: 0.5580 - val_loss: 1.2516\n",
      "Epoch 14/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5795 - loss: 1.1506 - val_accuracy: 0.5635 - val_loss: 1.2182\n",
      "Epoch 15/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5824 - loss: 1.1377 - val_accuracy: 0.5575 - val_loss: 1.2537\n",
      "Epoch 16/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6084 - loss: 1.0982 - val_accuracy: 0.5465 - val_loss: 1.2498\n",
      "Epoch 17/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5978 - loss: 1.1007 - val_accuracy: 0.5750 - val_loss: 1.2188\n",
      "Epoch 18/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6117 - loss: 1.0555 - val_accuracy: 0.5850 - val_loss: 1.1834\n",
      "Epoch 19/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6086 - loss: 1.0861 - val_accuracy: 0.5745 - val_loss: 1.2030\n",
      "Epoch 20/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6327 - loss: 1.0159 - val_accuracy: 0.5830 - val_loss: 1.1657\n",
      "Epoch 21/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6322 - loss: 1.0266 - val_accuracy: 0.5650 - val_loss: 1.2085\n",
      "Epoch 22/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6327 - loss: 1.0067 - val_accuracy: 0.4850 - val_loss: 1.5758\n",
      "Epoch 23/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6352 - loss: 0.9955 - val_accuracy: 0.6085 - val_loss: 1.1509\n",
      "Epoch 24/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6395 - loss: 0.9987 - val_accuracy: 0.5805 - val_loss: 1.1815\n",
      "Epoch 25/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6472 - loss: 0.9730 - val_accuracy: 0.5840 - val_loss: 1.1943\n",
      "Epoch 26/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6557 - loss: 0.9507 - val_accuracy: 0.5675 - val_loss: 1.2108\n",
      "Epoch 27/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6599 - loss: 0.9338 - val_accuracy: 0.5970 - val_loss: 1.1235\n",
      "Epoch 28/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6599 - loss: 0.9413 - val_accuracy: 0.5775 - val_loss: 1.2502\n",
      "Epoch 29/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6764 - loss: 0.9064 - val_accuracy: 0.5885 - val_loss: 1.1899\n",
      "Epoch 30/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6665 - loss: 0.9044 - val_accuracy: 0.6070 - val_loss: 1.1313\n"
     ]
    }
   ],
   "source": [
    "# Neural network parameters\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "batch_size = 64 # \n",
    "epochs = 30 # \n",
    "dropoutRate = 0.3\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=input_shape)) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(dropoutRate)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(dropoutRate)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "model.add(BatchNormalization())\n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dropout(dropoutRate)) # Value between 0 and 1 \n",
    "#-----------------------------------------------\n",
    "#-----------------------------------------------\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trainen van het CNN\n",
    "history = model.fit(X_train, y_train,batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=1, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4627920d8c10090b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4627920d8c10090b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further reading on tensorboard:\n",
    "https://www.tensorflow.org/tensorboard/get_started "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ea47f7",
   "metadata": {},
   "source": [
    "# Session 02 - Convolutional Neural Networks - Assignment\n",
    "\n",
    "## Goal of the assignment\n",
    "\n",
    "Convolutional Neural Networks are unmatched when it comes to image recognition tasks.\n",
    "In this assignment, you'll learn how to apply them to image data. It will involve designing you own custom CNN, but also applying transfer learning where you'll start from a pre-trained CNN and re-train it to your own classification task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2d577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 23:39:06.143102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-15 23:39:06.154639: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-15 23:39:06.157753: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-15 23:39:06.166656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-15 23:39:06.890460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "#import Tensorflow namespaces\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "# GPU\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d231db0",
   "metadata": {},
   "source": [
    "## Fashion MNIST with CNN\n",
    "\n",
    "The Fashion-MNIST dataset consists of thousands of grey-valued images of clothes from 10 different classes: 0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'.\n",
    "\n",
    "The training set and test set are provided.\n",
    "\n",
    "- Train and optimze a CNN achieving the highest possible accuracy on the test set. (do not forget to normalize your data)\n",
    "\n",
    "Write down some conclusions:\n",
    "- What is the achieved accuracy? How about the recall-values of the different classes?\n",
    "- Is there an imbalance between the performance on the different classes? Does the neural network have a preference for a certain class?\n",
    "- Visualize a couple of misclassified images. For examples the top 10 images with the highest loss. \n",
    "- Check if you neural network is suffering from overfitting and how you have applied regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8095a0aa-4151-4af1-af0a-c6f35efd6662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the fashion MNIST dataset\n",
    "df_train = pd.read_csv('./fashion-mnist_train.csv')\n",
    "df_test = pd.read_csv('./fashion-mnist_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f04138-81c3-4003-90de-26bb59034bdb",
   "metadata": {},
   "source": [
    "## CIFAR‑10 Image Classification\n",
    "In this assignment, you will design and train convolutional neural networks (CNNs) to classify images in the CIFAR-10 dataset. The demo code provided earlier is suboptimal, and your task is to improve upon it. Using proper techniques, an accuracy of at least 80% is achievable.\n",
    "\n",
    "You are encouraged to experiment with methods such as image augmentation (rotation, shift, flip, zoom), early stopping, and other strategies to improve performance. While you should avoid using the largest possible models, the focus of this assignment is on applying and combining different techniques to optimize your models. Examples include:\n",
    "\n",
    "- Image augmentation (rotation, flipping, shifting, zooming, etc.)\n",
    "- Hyperparameter tuning\n",
    "- Regularization techniques \n",
    "\n",
    "The focus of this assignment is not to use the *largest possible models*, but to **demonstrate your understanding** of CNN design and optimization. Showing that you experiment with and reason about different techniques is **more important** than simply achieving the highest numerical accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "Custom CNN\n",
    "\n",
    "1. **Design your own CNN architecture** for the CIFAR-10 dataset. Consider:\n",
    "   - Multiple convolutional and pooling layers\n",
    "   - Activation functions such as ReLU\n",
    "   - Dropout or batch normalization for regularization\n",
    "   - Dense layers for classification\n",
    "\n",
    "2. **Train your CNN** on the CIFAR-10 training set and evaluate it on the test set.\n",
    "\n",
    "3. **Write down your conclusions:**\n",
    "   - What is the achieved overall accuracy?\n",
    "   - Are some classes predicted better than others? Does your network show a preference for certain classes?\n",
    "   - Visualize several **misclassified images** and discuss possible reasons for the errors.\n",
    "   - Check for **overfitting** by plotting training vs. validation loss and accuracy.\n",
    "\n",
    "4. **Try to improve performance using:**\n",
    "   - Hyperparameter tuning\n",
    "   - Image augmentation (`ImageDataGenerator`)\n",
    "   - Early stopping\n",
    "   - Class weight balancing (if needed)\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d96144-cca6-48f1-a2ae-e87362a29ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 0us/step\n",
      "Training data shape: (50000, 32, 32, 3) (50000, 1)\n",
      "Test data shape: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10 \n",
    "\n",
    "# This will download CIFAR-10 and split it into training and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# test to see if dataset was downloaded correctly\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)\n",
    "# Expected output: \n",
    "# Training data shape: (50000, 32, 32, 3)  (50,000 RGB images)\n",
    "# Test data shape: (10000, 32, 32, 3)      (10,000 RGB images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bb1f6-d0f0-4625-8ef8-c31ef89c3adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "395cfec1-8c4c-4aaa-abbc-e3f65e0c1116",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "1. **Apply transfer learning** using a pre-trained CNN such as **VGG19** or **ResNet50**:\n",
    "\n",
    "   (https://keras.io/api/applications/resnet/)\n",
    "\n",
    "   \n",
    "   - Load the pre-trained model without the top classification layers (`include_top=False`)\n",
    "   - Add your own dense layers for CIFAR-10 classification\n",
    "   - Freeze the base model initially\n",
    "\n",
    "3. **Train and evaluate** your transfer learning model on CIFAR-10.\n",
    "\n",
    "4. **Compare the performance** with your custom CNN:\n",
    "   - Which achieved higher accuracy?\n",
    "   - Which generalized better?\n",
    "   - Are there specific classes both models struggled with?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "1. Summarize and compare the **performance** of your custom CNN and your transfer learning model:\n",
    "   - Report final accuracy for both models\n",
    "   - Comment on per-class performance and misclassifications\n",
    "   - Discuss which model suffers the most from overfitting\n",
    "\n",
    "2. Reflect on the **techniques you used** to improve performance:\n",
    "   - Which methods helped the most?\n",
    "   - How did data augmentation, regularization, or fine-tuning affect the results?\n",
    "\n",
    "3. Conclude with insights about the **trade-offs between custom models and transfer learning**, including considerations like training time, model size, and generalization ability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8de1db-ac8e-41bb-8701-54cdc3adfb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb973c-c867-4525-bcef-a3b9f425f2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

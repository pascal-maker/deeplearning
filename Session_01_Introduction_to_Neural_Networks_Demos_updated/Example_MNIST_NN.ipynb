{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 10:44:02.102397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-26 10:44:02.115146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-26 10:44:02.118588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-26 10:44:02.129516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-26 10:44:03.035979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758876243.740750   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1758876243.767501   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1758876243.767603   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "#Import Tensorflow namespaces\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "##### Tensorflow GPU ##########\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Split into features and targets\n",
    "\n",
    "train_labels = df_train.label.values\n",
    "test_labels = df_test.label.values\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "X_train = df_train.drop('label',axis=1).values\n",
    "X_test  = df_test.drop('label',axis=1).values\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principle Component Analysis\n",
    "number_of_components = 50\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca_model = PCA(n_components=number_of_components, svd_solver='full')\n",
    "pca_model.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_pca = pca_model.transform(X_train)\n",
    "X_test_pca = pca_model.transform(X_test)\n",
    "\n",
    "# Normalization\n",
    "\n",
    "X_train_pca = X_train_pca / X_train_pca.max()\n",
    "X_test_pca = X_test_pca / X_test_pca.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1758876259.941214   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1758876259.941379   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1758876259.941470   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1758876260.171394   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1758876260.171508   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-26 10:44:20.171520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1758876260.171590   20580 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-26 10:44:20.171614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Neural network initialization\n",
    "\n",
    "activation = 'relu'\n",
    "dropout_rate = 0.2\n",
    "kernel_initializer ='uniform'\n",
    "optimizer = 'adam'\n",
    "lr = 0.01\n",
    "batchsize = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=number_of_components, kernel_initializer=kernel_initializer,activation=activation))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(50, kernel_initializer=kernel_initializer,activation=activation))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758876261.679413   20688 service.cc:146] XLA service 0x7f282c00cb40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758876261.679451   20688 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-09-26 10:44:21.712417: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-26 10:44:21.855264: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 89/629\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2772 - loss: 2.2788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758876263.059278   20688 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5393 - loss: 1.6356 - val_accuracy: 0.8602 - val_loss: 0.4989\n",
      "Epoch 2/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.5497 - val_accuracy: 0.8900 - val_loss: 0.3831\n",
      "Epoch 3/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.4408 - val_accuracy: 0.9016 - val_loss: 0.3349\n",
      "Epoch 4/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.3908 - val_accuracy: 0.9117 - val_loss: 0.3026\n",
      "Epoch 5/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.3590 - val_accuracy: 0.9185 - val_loss: 0.2721\n",
      "Epoch 6/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.3251 - val_accuracy: 0.9243 - val_loss: 0.2546\n",
      "Epoch 7/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2956 - val_accuracy: 0.9327 - val_loss: 0.2317\n",
      "Epoch 8/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2902 - val_accuracy: 0.9339 - val_loss: 0.2212\n",
      "Epoch 9/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.2637 - val_accuracy: 0.9369 - val_loss: 0.2098\n",
      "Epoch 10/10\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.2394 - val_accuracy: 0.9414 - val_loss: 0.1957\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, y_train, epochs=10,validation_split=0.33, batch_size=batchsize,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "\n",
    "# Accuray \n",
    "plt.plot(history.history['accuracy'],'r')\n",
    "plt.plot(history.history['val_accuracy'],'b')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Loss \n",
    "plt.plot(history.history['loss'],'r')\n",
    "plt.plot(history.history['val_loss'],'b')\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#y_predicted = model.predict_classes(X_test_pca,batch_size=1, verbose=1)\n",
    "y_predicted = np.argmax(model.predict(X_test_pca),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 0 ... 7 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 0 ... 7 6 9]\n",
      "0.9468333333333333\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted)\n",
    "print(print(accuracy_score(test_labels, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1195\n",
      "           1       0.96      0.98      0.97      1352\n",
      "           2       0.95      0.94      0.95      1157\n",
      "           3       0.94      0.94      0.94      1258\n",
      "           4       0.93      0.94      0.94      1140\n",
      "           5       0.93      0.92      0.92      1076\n",
      "           6       0.96      0.97      0.97      1167\n",
      "           7       0.96      0.96      0.96      1268\n",
      "           8       0.94      0.93      0.93      1174\n",
      "           9       0.93      0.91      0.92      1213\n",
      "\n",
      "    accuracy                           0.95     12000\n",
      "   macro avg       0.95      0.95      0.95     12000\n",
      "weighted avg       0.95      0.95      0.95     12000\n",
      "\n",
      "[[1174    0    2    1    1    6    4    0    7    0]\n",
      " [   0 1325    3    4    2    4    0    4    9    1]\n",
      " [  11    2 1090    7   10    4   10   11   11    1]\n",
      " [   1    4   17 1183    0   26    4    8   10    5]\n",
      " [   1    9    4    0 1073    0    9    0    3   41]\n",
      " [  12    7    1   27    8  986   10    2   15    8]\n",
      " [  12    4    7    0    4    8 1128    0    4    0]\n",
      " [   5    4   15    6    5    2    1 1214    2   14]\n",
      " [   7   25    6   16    5   16    3    1 1086    9]\n",
      " [   8    5    2   15   41   12    0   19    8 1103]]\n",
      "94.68333333333334\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "print(classification_report(test_labels, y_predicted))\n",
    "\n",
    "cf = confusion_matrix(test_labels, y_predicted)\n",
    "\n",
    "print(cf)\n",
    "print(accuracy_score(test_labels, y_predicted) * 100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', activation='relu', dropout_rate=0.0, kernel_initializer='uniform', neurons=10):\n",
    "    \"\"\"\n",
    "    Creates and returns a Sequential neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    - optimizer (str): The optimizer to use for training (default: 'adam').\n",
    "    - activation (str): The activation function to use in the hidden layers (default: 'relu').\n",
    "    - dropout_rate (float): The dropout rate to apply after each hidden layer (default: 0.0).\n",
    "    - kernel_initializer (str): The initializer for the weights of the layers (default: 'uniform').\n",
    "    - neurons (int): The number of neurons in each hidden layer (default: 10).\n",
    "\n",
    "    Returns:\n",
    "    - model (Sequential): The compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    # Initialize a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer and first hidden layer\n",
    "    # 'neurons' specifies the number of neurons in the layer\n",
    "    # 'input_dim' specifies the number of input features (number_of_components)\n",
    "    # 'kernel_initializer' initializes the weights\n",
    "    # 'activation' specifies the activation function\n",
    "    model.add(Dense(neurons, input_dim=number_of_components, kernel_initializer=kernel_initializer, activation=activation))\n",
    "\n",
    "    # Apply dropout to reduce overfitting\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Second hidden layer\n",
    "    model.add(Dense(neurons, kernel_initializer=kernel_initializer, activation=activation))\n",
    "\n",
    "    # Apply dropout again to reduce overfitting\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    # 10 neurons for 10 output classes (e.g., digits 0-9 in MNIST)\n",
    "    # 'softmax' activation for multi-class classification\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    # Loss function: Categorical cross-entropy for multi-class classification\n",
    "    # Optimizer: Specified by the 'optimizer' parameter (default: 'adam')\n",
    "    # Metrics: Accuracy to evaluate model performance\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3285 - loss: 1.9331\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6688 - loss: 1.0002\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.7607\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.7058\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7725 - loss: 0.6686\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.6131\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.5550\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 0.4995\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.4558\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.4417\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.4050\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3847\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.3532\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3465\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.3364\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.3237\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.3166\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.3132\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2893\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2941\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3019\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2833\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2890\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2821\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2752\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2759\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2753\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2720\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2629\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2754\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2631\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2666\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2649\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2685\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2580\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2581\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2652\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2593\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2561\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2525\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2658\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2636\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2584\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2527\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2493\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2399\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2490\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2546\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2485\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2481\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 1/5] END batch_size=16, epochs=50, optimizer=SGD;, score=0.924 total time= 2.7min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2946 - loss: 1.9635\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.9143\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.6734\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.5878\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.5392\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.4846\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.4688\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.4454\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.4028\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.3900\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.3749\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3562\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.3681\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.3414\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.3447\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.3419\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.3330\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.3387\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.3293\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.3212\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.3187\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.3167\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.3182\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.3060\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2970\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.3027\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.3046\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.3002\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2962\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.3037\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2931\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2938\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2881\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2936\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2773\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2869\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2804\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2824\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2831\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2775\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2792\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2638\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2708\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2725\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2699\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2625\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2578\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2689\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.2653\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2510\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/5] END batch_size=16, epochs=50, optimizer=SGD;, score=0.911 total time= 2.7min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2758 - loss: 2.0137\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 1.0055\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.6039\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.4956\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.4379\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.4186\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3951\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.3608\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3683\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.3496\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9020 - loss: 0.3331\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.3306\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.3277\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.3043\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3082\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2993\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2973\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2869\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2957\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2872\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2878\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2811\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2734\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2738\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2793\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2716\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2725\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2698\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2718\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2695\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2672\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2636\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2679\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2575\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2630\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2578\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2615\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2576\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2530\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2567\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2499\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2466\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.2511\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2435\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2536\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2516\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2447\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2548\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.2475\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2470\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 3/5] END batch_size=16, epochs=50, optimizer=SGD;, score=0.921 total time= 2.8min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3289 - loss: 1.8902\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7840 - loss: 0.7406\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.5856\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.5425\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.4939\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.4574\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.4308\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3997\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3823\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.3764\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.3476\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.3521\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.3311\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3233\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.3209\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.3150\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.3064\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3025\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.3077\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.3001\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2876\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.3011\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2825\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2748\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2918\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2617\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2728\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2806\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2683\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2589\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2602\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2535\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2499\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2483\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2467\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2512\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2454\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2393\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2404\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2348\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2458\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2320\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2353\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.2429\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2399\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.2323\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.2372\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2340\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.2345\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2257\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 4/5] END batch_size=16, epochs=50, optimizer=SGD;, score=0.925 total time= 3.1min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2831 - loss: 1.9050\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.8822\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.6258\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.5370\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.4563\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.4233\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.3924\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.3779\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.3601\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.3470\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.3456\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.3267\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.3085\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.3106\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2959\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.3064\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2984\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2827\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2866\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2635\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2669\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2645\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2724\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2633\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2616\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2628\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2571\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2610\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2600\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2559\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2565\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2503\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2473\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2520\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2454\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2417\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2392\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2483\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2492\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2420\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2476\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2475\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2319\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2410\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.2340\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.2298\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.2457\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.2306\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2493\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.2383\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 5/5] END batch_size=16, epochs=50, optimizer=SGD;, score=0.920 total time= 2.8min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3665 - loss: 1.8645\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.7061\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.5411\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.4709\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.4517\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.4294\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.4095\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3985\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3918\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.3746\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.3807\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.3596\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.3399\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.3380\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.3213\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.3147\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3235\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.3106\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3034\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2998\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.3058\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.3048\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.3019\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2930\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2976\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2890\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2920\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2945\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2905\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2935\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2921\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2827\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2905\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2865\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2800\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2820\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2777\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2762\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2720\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2813\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2842\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2815\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2809\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2713\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2749\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2761\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2722\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2657\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2605\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2692\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 1/5] END batch_size=16, epochs=50, optimizer=Adam;, score=0.919 total time= 3.4min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3208 - loss: 1.9043\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.9845\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.7822\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.6635\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.5870\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.5297\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.4839\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.4491\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.4015\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.3852\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3620\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.3447\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.3297\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.3220\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.3135\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.3077\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2930\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2905\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2780\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2866\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2797\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2698\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2730\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2685\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2706\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2689\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2593\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2671\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2576\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2525\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2569\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2524\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2500\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2492\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2438\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2490\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2465\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2460\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2404\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2394\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.2443\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2289\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2335\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2321\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.2297\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2347\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.2389\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2319\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.2297\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.2335\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 2/5] END batch_size=16, epochs=50, optimizer=Adam;, score=0.920 total time= 2.3min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3960 - loss: 1.8047\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.7550\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.5864\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.5068\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.4817\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.4594\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.4225\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.3990\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.3821\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.3795\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.3556\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.3496\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.3483\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3382\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.3320\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.3256\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.3206\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.3162\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.3144\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.3051\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.3048\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.3017\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.3002\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2819\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2924\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2887\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2649\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2786\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2775\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2750\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2745\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2777\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2668\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2644\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2627\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.2699\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2584\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2649\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2569\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2629\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2599\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2576\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2612\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2584\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2434\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2508\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2493\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2475\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.2501\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2533\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 3/5] END batch_size=16, epochs=50, optimizer=Adam;, score=0.917 total time= 2.3min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4468 - loss: 1.7264\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.6813\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.5025\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.4465\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.3976\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.3865\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.3660\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.3315\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9014 - loss: 0.3343\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.3188\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2998\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.3018\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2863\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2922\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2734\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2805\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2725\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2613\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.2560\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2623\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2553\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2475\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2533\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2436\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.2403\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2514\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.2419\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.2458\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2425\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.2342\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9306 - loss: 0.2311\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.2309\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.2272\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9301 - loss: 0.2309\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.2224\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2342\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.2231\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.2228\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.2234\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2213\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.2258\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2177\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2192\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2136\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.2167\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.2094\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2159\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.2078\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.2299\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9306 - loss: 0.2229\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 4/5] END batch_size=16, epochs=50, optimizer=Adam;, score=0.926 total time= 3.7min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3859 - loss: 1.8761\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7402 - loss: 0.8555\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.6202\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.5009\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.4232\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.3961\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.3669\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3561\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.3504\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.3407\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3204\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.3247\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.3108\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.3190\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.3068\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2952\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2952\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.3014\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2983\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2874\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2898\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2847\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2805\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2775\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2825\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.2698\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2636\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2638\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2693\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2678\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2637\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2562\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2644\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2599\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2593\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2529\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2465\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.2674\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2539\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2595\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2556\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2496\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2590\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.2520\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2515\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2505\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.2522\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2484\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2501\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2491\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 5/5] END batch_size=16, epochs=50, optimizer=Adam;, score=0.919 total time= 3.0min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2143 - loss: 2.0919\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6434 - loss: 1.1223\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.7517\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.5654\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.5085\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.4814\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8644 - loss: 0.4536\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.4210\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.4034\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3989\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3833\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.3731\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.3746\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.3570\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.3437\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.3448\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.3359\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.3393\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.3182\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.3360\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3182\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3032\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2984\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.3042\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.3021\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2882\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.3012\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2994\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2914\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2918\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2794\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2773\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2765\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2842\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2760\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2756\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2760\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2782\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2705\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2725\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.2597\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2713\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2676\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2594\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2486\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2633\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2461\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.2584\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2562\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2491\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "[CV 1/5] END batch_size=32, epochs=50, optimizer=SGD;, score=0.923 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2354 - loss: 2.0771\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 1.0470\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7598 - loss: 0.7854\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.6974\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.6339\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.5652\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.5017\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.4604\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.4513\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.4251\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.4018\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.3861\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.3586\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.3503\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.3430\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.3373\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.3262\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.3143\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.3038\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2982\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.3049\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2943\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2908\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2793\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2887\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2753\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2686\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2787\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2638\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2661\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2716\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2666\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2607\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2686\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.2517\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2556\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2578\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2455\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2494\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.2487\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2531\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2447\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.2409\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2548\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2516\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2409\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2423\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.2414\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2363\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.2421\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 2/5] END batch_size=32, epochs=50, optimizer=SGD;, score=0.923 total time= 1.6min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2625 - loss: 2.0794\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 1.0033\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.7269\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.6420\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.5852\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.5461\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.5108\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.4911\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.4642\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.4485\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.4401\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.4288\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.4183\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.4110\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3947\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.3857\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3728\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.3560\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.3500\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.3525\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3424\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.3332\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.3267\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.3198\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.3127\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.3128\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.3105\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.3087\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3011\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2880\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2956\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2824\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2767\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2768\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2849\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2836\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2757\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2743\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2706\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2757\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2676\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.2678\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2529\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2665\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2606\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2603\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2526\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2520\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2527\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2588\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[CV 3/5] END batch_size=32, epochs=50, optimizer=SGD;, score=0.914 total time= 1.4min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2336 - loss: 2.0711\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.9636\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.7008\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.6179\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.5451\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.5112\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.4781\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.4644\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.4442\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.4194\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3970\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.3960\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.3804\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3624\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.3703\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.3538\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.3407\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.3412\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.3402\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.3372\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.3275\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.3220\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.3326\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.3168\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.3210\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3139\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.3061\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.3113\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.3055\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.3093\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.3085\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.3050\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2974\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2943\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.3010\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2907\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2874\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2813\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2876\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2938\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2887\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2685\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2810\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2794\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2788\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2799\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2684\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2757\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2730\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2733\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 4/5] END batch_size=32, epochs=50, optimizer=SGD;, score=0.911 total time= 1.4min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2975 - loss: 2.0641\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.9339\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.7103\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.6018\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.5495\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.4933\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.4803\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.4344\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8756 - loss: 0.4281\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3937\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.3788\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.3569\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.3442\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3261\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.3253\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.3116\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.3057\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2995\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2850\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2839\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2841\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2921\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2836\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2900\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2718\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2758\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2764\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2689\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2777\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2669\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2712\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2820\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2624\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2658\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2650\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2622\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2546\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2562\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2603\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2663\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2583\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2605\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2542\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2473\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2455\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2536\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2461\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2424\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2556\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2546\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 5/5] END batch_size=32, epochs=50, optimizer=SGD;, score=0.917 total time= 1.5min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3789 - loss: 2.0317\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.9069\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.7128\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.6148\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.5376\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.4854\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.4461\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.4089\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.3882\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.3892\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.3724\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.3507\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.3517\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.3321\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.3244\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.3201\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2999\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.3113\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.3003\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2952\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2983\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2939\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2842\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2937\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2786\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2770\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2879\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2671\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2684\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2641\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2632\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2644\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2585\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2527\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2705\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2596\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2616\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2461\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2514\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2521\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2477\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2589\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2605\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2440\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2499\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2580\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2485\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2498\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2484\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2525\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/5] END batch_size=32, epochs=50, optimizer=Adam;, score=0.926 total time= 1.4min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2640 - loss: 2.0690\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.8125\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8303 - loss: 0.5859\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.4921\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.4494\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.4165\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.3930\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3846\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.3688\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.3531\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3593\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3429\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.3308\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.3313\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.3270\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.3193\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3198\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.3089\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.3039\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2969\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2891\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2965\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2867\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2686\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2871\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2620\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2690\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2690\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2691\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2541\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2519\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2628\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2558\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2608\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2541\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2519\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2545\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2438\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2500\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2419\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2425\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2486\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2414\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2366\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2487\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2370\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2388\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2378\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2336\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.2408\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/5] END batch_size=32, epochs=50, optimizer=Adam;, score=0.921 total time= 1.3min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2496 - loss: 2.0795\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6961 - loss: 1.0062\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.7265\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.5927\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.5148\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.4890\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.4563\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.4342\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.4240\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.3975\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.3872\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.3802\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.3758\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.3566\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.3440\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.3331\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3311\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3253\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.3313\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.3174\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.3097\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3107\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2997\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2989\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2980\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2898\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2882\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2883\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2757\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2776\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2773\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2739\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2793\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2680\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2718\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2694\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2730\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2651\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2676\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2705\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2680\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2589\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.2554\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.2652\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.2486\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2556\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2531\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2422\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2481\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.2612\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[CV 3/5] END batch_size=32, epochs=50, optimizer=Adam;, score=0.916 total time= 1.9min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2622 - loss: 2.0594\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6353 - loss: 1.0772\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.7995\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.6924\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.5986\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.5514\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.5027\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.4788\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.4726\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.4325\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.4094\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.3879\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.3783\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3781\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.3628\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.3433\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.3410\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3304\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.3196\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.3139\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.3062\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.3003\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2901\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2734\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2753\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2733\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2792\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2693\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2703\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2679\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2472\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2591\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2579\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2506\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2487\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2470\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2506\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2454\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2411\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2436\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2361\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2415\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2430\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2484\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2439\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2419\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.2404\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2264\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2399\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2406\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 4/5] END batch_size=32, epochs=50, optimizer=Adam;, score=0.923 total time= 1.5min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2406 - loss: 2.1349\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 1.0185\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.7132\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.5882\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.5207\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.4786\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.4575\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.4163\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.4142\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.3889\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.3762\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.3747\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.3643\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.3572\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.3532\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.3470\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.3423\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.3258\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.3342\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.3246\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3196\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.3104\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.3049\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3094\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.3162\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.3020\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.3193\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.3136\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.3054\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2901\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2938\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2894\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2954\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2844\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2826\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2838\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2718\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2760\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2803\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2787\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2804\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2720\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2694\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2703\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2666\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2601\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2656\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2548\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2482\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2607\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 5/5] END batch_size=32, epochs=50, optimizer=Adam;, score=0.916 total time= 1.3min\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcldwitt/.local/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/mcldwitt/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3352 - loss: 1.8926\n",
      "Epoch 2/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6827 - loss: 0.9775\n",
      "Epoch 3/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7899 - loss: 0.6570\n",
      "Epoch 4/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.5587\n",
      "Epoch 5/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.4887\n",
      "Epoch 6/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8790 - loss: 0.4131\n",
      "Epoch 7/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3725\n",
      "Epoch 8/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.3488\n",
      "Epoch 9/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.3435\n",
      "Epoch 10/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.3211\n",
      "Epoch 11/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.3105\n",
      "Epoch 12/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.3148\n",
      "Epoch 13/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.3045\n",
      "Epoch 14/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2987\n",
      "Epoch 15/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2898\n",
      "Epoch 16/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2920\n",
      "Epoch 17/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2836\n",
      "Epoch 18/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2760\n",
      "Epoch 19/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2778\n",
      "Epoch 20/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2667\n",
      "Epoch 21/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2673\n",
      "Epoch 22/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2668\n",
      "Epoch 23/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2537\n",
      "Epoch 24/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2519\n",
      "Epoch 25/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2465\n",
      "Epoch 26/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2488\n",
      "Epoch 27/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2470\n",
      "Epoch 28/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2410\n",
      "Epoch 29/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2442\n",
      "Epoch 30/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2416\n",
      "Epoch 31/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2434\n",
      "Epoch 32/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2449\n",
      "Epoch 33/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2408\n",
      "Epoch 34/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2471\n",
      "Epoch 35/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2366\n",
      "Epoch 36/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.2367\n",
      "Epoch 37/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.2330\n",
      "Epoch 38/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.2283\n",
      "Epoch 39/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2323\n",
      "Epoch 40/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.2257\n",
      "Epoch 41/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2325\n",
      "Epoch 42/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.2260\n",
      "Epoch 43/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2268\n",
      "Epoch 44/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2360\n",
      "Epoch 45/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2361\n",
      "Epoch 46/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.2227\n",
      "Epoch 47/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2298\n",
      "Epoch 48/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.2255\n",
      "Epoch 49/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2205\n",
      "Epoch 50/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.2207\n"
     ]
    }
   ],
   "source": [
    "# Import KerasClassifier for wrapping the Keras model\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Import GridSearchCV for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Wrap the `create_model` function in a KerasClassifier\n",
    "# This allows the model to be used with scikit-learn tools like GridSearchCV\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batchsize, epochs=10)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "neurons = [5, 10, 20, 30, 40, 50]  # Number of neurons in the hidden layers\n",
    "init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']  # Weight initializers\n",
    "optimizer = ['SGD', 'Adam']  # Optimizers to test\n",
    "# Uncomment the following line to test additional optimizers\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "epochs = [50]  # Number of epochs to test\n",
    "batch_size = [16, 32]  # Batch sizes to test\n",
    "\n",
    "# Create a dictionary of hyperparameters to test\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size, optimizer=optimizer)\n",
    "\n",
    "##############################################################\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=3)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "# This will train the model for each combination of hyperparameters in `param_grid`\n",
    "grid_result = grid.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.920467 using {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.920200 (0.005096) with: {'batch_size': 16, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.920467 (0.002821) with: {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.917700 (0.004687) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.920333 (0.004062) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
